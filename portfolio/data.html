<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head> 
<title>Data &amp; Data Quality</title>
<meta name="keywords" content="" />
<meta name="description" content="" />
<meta name="author" content="" />
<meta http-equiv="content-type" content="text/html;charset=utf-8" />
<meta http-equiv="Content-Style-Type" content="text/css" />
<link rel="stylesheet" href="css/blueprint/screen.css" type="text/css" media="screen, projection" />
<link rel="stylesheet" href="css/blueprint/print.css" type="text/css" media="print" />
<link rel="stylesheet" href="css/main.css" type="text/css" media="screen" /> 
<!--[if IE]>
  <link rel="stylesheet" href="css/blueprint/ie.css" type="text/css" media="screen, projection">
<![endif]-->
</head>
<body>
<div class="container">
  <h1>Data Mining Portfolio</h1>
  <h2>Data and Quality</h2>
  <p class="introduction">The core of any data mining project is the data being mined. This data comes in many different forms and often requires cleaning prior to applying data mining techniques. It is also important to look at the data prior to mining inorder to help identify potential problems. Creating a visualization can also provide important information about the data as well as giving a client something tangible to examine.</p>
<h3>Datasets</h3>
<p class="introduction">Market basket data is a dataset that is typically very wide. The dataset usually contains a column for every item or every type of item in a store. This data is occasionally given to the data miner as a series of lists showing each customers purchases. In this case it is important to pre-process this data into columns of each item with a 1 for purchased and a 0 for not purchased. Market basket data uses different methods later on during the process becasue the data is very sparse, most people only buy a small portion of the items available in a store so most records look very similar, almost all 0's.</p>
<p class="introduction">Survey Data often has missing information where a question wasn't answered or the answer was unreadable. Surveys can also have non-structured data such as a written response. These present different challenges: How do you mine those written responses? Qhat do you do with a blank answer? This data also is more subjective, often with two people who feel the same about a product one will give it a 5/5 and another will give it a 3/5.</p>
<P class="introduction">Recorded data is usually recorded over time. This creates a time dependance between records, the first record and second record occur closer together than the first and fifth records do. This causes the order of the records to be important. If there is no time associated with the records it can be a good idea to include the index of the record as an attribute to capture the time dependance. During the datamining process it is important to consider that records that were recorded close together will most likely be very similar, in some cases giving a long line of datapoints instead of normally distributed data points. This can cause problems when analysing the data.</p>
<h3>Data Attributes</h3>
<p class="introduction">Binary attributes take two values, true and false. This data is in many ways the easiest to use, if two records both have a true for a attribute, then they are perfectly similar with respect to that attribute. Binary attributes are what comprise market basket data, gender and many other data elements.</p>
<p class="introduction">Nominal attributes take discrete values such as {1,2,3,4,5}. In nominal data the order isn't important so a 1 and a 2 are just as different as a 1 and a 3 are. These numbers often correspond to categories, for example race: black=1, white=2, other=3. This causes some problems in data mining because most people looking at the data would say 1 is closer to 2 so they must be more similar. The simplest way to correct the order problem is to break nominal attributes into a series of binary attributes. This would change the example to 3 different attributes: isWhite, isBlack, isOther. Nominal attributes are very common and usually require some work prior to starting data mining strategies.</p>
<p class="introduction">Ordinal attributes are similar to nominal attributes, they take on discrete values; however in ordinal attributes, order does matter. Because order matters there is no need to preprocess ordinal attributes into binary attributes and they are still easy to work with. Data that is commonly ordinal is movie ratings. A 1 start rating becomes a 1 and a 5 star rating becomes a 5. Obviously a 5 is more similar to a 4 which is what makes this data ordinal.</p>
<p class= "introduction">Continuous attribues are essentially real numbers. Tempature is a simple example, temperature is continuous it doesn't just jump from 40 to 41 degrees there is a slow change between the two. Continuous attributes behave like ordinal attributes in most data mining.</p>
<p class="introduction">Unstructured attributes are things like video or text where there is no simple way to determine what the real meaning is. How unstructured data is delt with differs based on what industry you are in. Reviews are often broken into positive and negative aspects using keywords while searching uses word vectors to determine how close the seach is to the page. Unstructured data will always require preprocessing to create attributes that data mining algorithms can process.</p>
<h3>Dealing With Data</h3>
<p class="introduction">All datasets in the real world have problems with them. Instead of using normalized data in a database companies will hand enter all records into an excel spreadsheet, or will create a database that doesn't follow normalization rules. In both cases this causes significant errors in the data such as misentered names or values. In the case of misentered names finding and mapping them to the proper name can be easy, just make a list of all names that occur in the data and let someone familiar with the data fix the mistake globally (eg. Csotco instead of Costco) this will fix most of the name errors. There are still some that will not be caught, the person entering the data may have entered the wrong name into the spreadsheet, this error is almost impossible to fix. Errors with values are more difficult to find. In many cases they are impossible to catch, the difference between 1,232 pounds is very similar to 1,223 pounds. Programatically you can catch some transpositions because they appear as an anomaly such as 1,232 pounds vs. 2,132 pounds. Other possible transpositions is to switch pound and dollar values causeing a calculation like Average Sales Price to change from less than 1 to greater than 1. Fixing these errors is a major part of data cleaning.</p> 
<p class="introduction">Missing values are also a problem, when dealing with multiple data sets at a time this is even more common. One grade in a school may track the NWEA and CSAP scores for a student while a different grade only tracks CSAP scores. What do you put as the value for the NWEA score in the second class? Giving each student a zero doesn't make sense nor does giving them a perfect score. This missing data can be populated with an average score in some cases or by calculating an approximate score based on other data. These substituted values are not shown to an end user because they are misleading but are just used in calculations. Another portion of data that can be missing is an attribute such as Teacher Name. This missing data doesn't indicate a value is missing just some information about the value. The most common fix for this missing data is to replace all missing attributes with a "Not assigned" label or some similar label. This puts all missing values into the same class for the particular attribute.</p>
<h3>Visualizing Data</h3>
<p class="intorduction">Most clients are interested in seeing some representation of the data. This can mean something as simple as a graph with a time scale on the x axis and a sales total on the y axis. These simple visualizations are a great place to start, they are tried and true and easy to understand for a non technical user. This method is very restrictive however, only one attribute and one value may be displayed. A more flexible but less visual approch to slightly expand this is to use a table. A basic table allows for one attribute and no restrictions of the number of values. It is important to make tracing across these records easy otherwise this data becomes unreadeable.</p>
<p class="introduction">It is possible to extend the baisic table. Nesting the values inside an attribute gives two attributes and no restriction in values. This would appear as a table with one attribute in the top row and one in the first column. In the second row the list of values repeats for each of the attributes in the top row. This works well as long as there are not too many values and the attribute on the top row is small because the table grows rapidly horizontally. Another extension is to create an attribute hierarchy for the right side of the table. This hierarchy is expandable to help only show the data the user is interested in. This is the solution I typically use for data display.</p>
<p class="introduction">In some cases other visualizations are necessary. Hyper-dimensional scaling is a quick way to "flatten" data to a two dimensional view. To do this the distance is calculated between each pair of points, and each point is randomly placed on a plane. Each pair compares the distance in the plane to what the distance should be and creates the gradient for the pair. Each point gets a gradient based of all associated pairs and moves the points along the gradient. This repeats until there is no or negative improvement in the error. The location of each point is then displayed to the user. This representation isn't really accurate but it is a simple way to represent the data.</p>
<p class="introduction">Visualization should be used throughout the data mining process. Seeing the data gives clues as to what a data miner should do next. The most important time for visualization however is the end product. Finding a good visualization to show to the client or the head of the project goes a long way to creating a good product and showing the data in a way that makes sense to the end user.</p>
</div>
</body>
</html>
